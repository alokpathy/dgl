0: Using backend: pytorch
0: WARNING:root:The OGB package is out of date. Your version is 1.3.0, while the latest version is 1.3.1.
0: Namespace(aggregator_type='gcn', dataset='reddit', dist_backend='gloo', dist_url='env://', dropout=0.0, gpu=-1, hostname='127.0.0.1', lr=0.01, n_epochs=10, n_hidden=16, n_layers=2, normalization=False, rank=-1, replication=1, weight_decay=0.0005, world_size=-1)
0: Loaded dataset reddit
0: ----Data statistics------'
0:           #Edges 114615892
0:           #Classes 41
0:           #Train samples 153431
0:           #Val samples 23831
0:           #Test samples 55703
0: hostname: nid00152 rank: 0
0: hostname: nid00152 rank: 0 size: 1
0: Processes: 1
0: rank: 0 adj_matrix_loc.size: torch.Size([232965, 232965])
0: rank: 0 inputs_loc.size: torch.Size([232965, 602])
0: i: 0 ampbyp.size: torch.Size([232965, 232965])
0: 
0: Test Accuracy 0.4622
0: 
0: /global/homes/a/alokt/.local/cori/pytorch1.7.1/lib/python3.8/site-packages/dgl-0.6-py3.8-linux-x86_64.egg/dgl/data/utils.py:285: UserWarning: Property dataset.graph will be deprecated, please use dataset[0] instead.
0:   warnings.warn('Property {} will be deprecated, please use {} instead.'.format(old, new))
0: train_full_15d.py:312: UserWarning: This overload of nonzero is deprecated:
0: 	nonzero()
0: Consider using one of the following signatures instead:
0: 	nonzero(*, bool as_tuple) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:882.)
0:   train_nid = train_mask.nonzero().squeeze()
0: /usr/common/software/pytorch/1.7.1/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py:126: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
0:   warnings.warn("torch.distributed.reduce_op is deprecated, please use "
0: Timings
0: rank: 0 timings: {'total': 44.97435903549194, 'scomp': 42.155579566955566, 'dcomp': 0.18206381797790527, 'bcast': 0.0037636756896972656, 'reduce': 0.0050275325775146484, 'op': 0.1887054443359375, 'barrier': 4.839897155761719e-05, 'broad_func': 43.49023675918579, 'mlp': 0.3716118335723877, 'forward': 42.535845041275024, 'backward': 2.389694929122925, 'forward_agg': 42.399566411972046, 'forward_mlp': 0.12227177619934082, 'forward_actdrop': 0.004400014877319336, 'comp': 42.33764338493347, 'comm': 0.19749665260314941}
