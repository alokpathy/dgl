Namespace(attn_drop=0.6, batch_size=1000, data_cpu=False, dataset='ogbn-products', dropout=0.5, eval_every=5, fan_out='100,200', gpu=0, in_drop=0.6, inductive=False, log_every=20, lr=0.003, negative_slope=0.2, num_epochs=3, num_heads=8, num_hidden=8, num_layers=1, num_out_heads=1, num_workers=4, residual=False, sample_gpu=False)
load ogbn-products
finish loading ogbn-products
finish constructing ogbn-products
Graph(num_nodes=2449029, num_edges=126167053,
      ndata_schemes={'feat': Scheme(shape=(100,), dtype=torch.float32), 'features': Scheme(shape=(100,), dtype=torch.float32), 'labels': Scheme(shape=(), dtype=torch.int64), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}
      edata_schemes={})
GAT(
  (gat_layers): ModuleList(
    (0): GATConv(
      (fc): Linear(in_features=100, out_features=64, bias=False)
      (feat_drop): Dropout(p=0.6, inplace=False)
      (attn_drop): Dropout(p=0.6, inplace=False)
      (leaky_relu): LeakyReLU(negative_slope=0.2)
    )
    (1): GATConv(
      (fc): Linear(in_features=64, out_features=47, bias=False)
      (feat_drop): Dropout(p=0.6, inplace=False)
      (attn_drop): Dropout(p=0.6, inplace=False)
      (leaky_relu): LeakyReLU(negative_slope=0.2)
    )
  )
)
Using backend: pytorch
Epoch 00000 | Step 00000 | Loss 113.7880 | Train Acc 0.0190 | Speed (samples/sec) nan | GPU 4176.9 MB
Epoch 00000 | Step 00020 | Loss 23.9084 | Train Acc 0.0900 | Speed (samples/sec) 2577.8126 | GPU 4200.9 MB
Epoch 00000 | Step 00040 | Loss 10.9519 | Train Acc 0.0990 | Speed (samples/sec) 2484.0882 | GPU 4226.1 MB
Epoch 00000 | Step 00060 | Loss 4.8904 | Train Acc 0.1250 | Speed (samples/sec) 2517.0817 | GPU 4240.4 MB
Epoch 00000 | Step 00080 | Loss 4.3958 | Train Acc 0.1910 | Speed (samples/sec) 2575.4191 | GPU 4240.4 MB
Epoch 00000 | Step 00100 | Loss 4.0472 | Train Acc 0.2190 | Speed (samples/sec) 2578.5737 | GPU 4240.4 MB
Epoch 00000 | Step 00120 | Loss 3.2792 | Train Acc 0.2740 | Speed (samples/sec) 2603.1754 | GPU 4241.1 MB
Epoch 00000 | Step 00140 | Loss 3.3126 | Train Acc 0.2460 | Speed (samples/sec) 2614.9820 | GPU 4241.1 MB
Epoch 00000 | Step 00160 | Loss 3.1126 | Train Acc 0.2360 | Speed (samples/sec) 2624.5249 | GPU 4241.1 MB
Epoch 00000 | Step 00180 | Loss 2.9523 | Train Acc 0.2660 | Speed (samples/sec) 2628.4881 | GPU 4241.1 MB
Epoch Time(s): 116.7074
/home/ubuntu/anaconda3/envs/dgl-conda/lib/python3.6/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.
  out=out, **kwargs)
/home/ubuntu/anaconda3/envs/dgl-conda/lib/python3.6/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
Epoch 00001 | Step 00000 | Loss 2.8743 | Train Acc 0.2630 | Speed (samples/sec) 2680.5632 | GPU 4241.1 MB
Epoch 00001 | Step 00020 | Loss 2.7600 | Train Acc 0.2840 | Speed (samples/sec) 2686.5265 | GPU 4241.1 MB
Epoch 00001 | Step 00040 | Loss 2.6840 | Train Acc 0.2950 | Speed (samples/sec) 2643.1870 | GPU 4241.1 MB
Epoch 00001 | Step 00060 | Loss 2.6726 | Train Acc 0.2910 | Speed (samples/sec) 2650.5544 | GPU 4241.1 MB
Epoch 00001 | Step 00080 | Loss 2.5579 | Train Acc 0.2960 | Speed (samples/sec) 2635.6043 | GPU 4241.1 MB
Epoch 00001 | Step 00100 | Loss 2.5607 | Train Acc 0.3250 | Speed (samples/sec) 2632.8685 | GPU 4241.1 MB
Epoch 00001 | Step 00120 | Loss 2.4861 | Train Acc 0.3270 | Speed (samples/sec) 2628.3405 | GPU 4241.1 MB
Epoch 00001 | Step 00140 | Loss 2.4316 | Train Acc 0.3620 | Speed (samples/sec) 2621.7606 | GPU 4241.1 MB
Epoch 00001 | Step 00160 | Loss 2.3540 | Train Acc 0.3690 | Speed (samples/sec) 2621.1209 | GPU 4242.2 MB
Epoch 00001 | Step 00180 | Loss 2.2559 | Train Acc 0.4000 | Speed (samples/sec) 2621.6350 | GPU 4242.2 MB
Epoch Time(s): 115.1957
block: Block(num_src_nodes=1179475, num_dst_nodes=108448, num_edges=8139837) h.size: torch.Size([1179475, 100])
-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                           Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  
-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
                  rf-leaky-relu         2.88%       2.324ms        23.83%      19.247ms      19.247ms     216.410us         0.27%      19.247ms      19.247ms             1  
                     rf-softmax        22.04%      17.806ms        22.88%      18.484ms      18.484ms      52.391us         0.06%      18.485ms      18.485ms             1  
                    EdgeSoftmax         0.57%     460.737us         0.84%     676.582us     676.582us      13.921ms        17.24%      18.433ms      18.433ms             1  
                       aten::to         0.03%      20.865us        20.85%      16.844ms      16.844ms      28.801us         0.04%      16.842ms      16.842ms             1  
                    aten::copy_        20.81%      16.814ms        20.81%      16.814ms      16.814ms      16.814ms        20.82%      16.814ms      16.814ms             1  
           rf-attn-dot-products        12.47%      10.070ms        12.73%      10.283ms      10.283ms      63.613us         0.08%      10.285ms      10.285ms             1  
                        rf-spmm        11.19%       9.038ms        11.52%       9.306ms       9.306ms     370.742us         0.46%       9.308ms       9.308ms             1  
                          GSpMM         0.27%     221.894us         0.33%     266.683us     266.683us       8.780ms        10.87%       8.937ms       8.937ms             1  
                  aten::dropout         0.04%      31.281us         0.22%     177.231us      88.615us      23.256us         0.03%       7.677ms       3.838ms             2  
           aten::_fused_dropout         0.13%     102.193us         0.18%     145.950us      72.975us       7.654ms         9.48%       7.654ms       3.827ms             2  
                          rf-FC         9.03%       7.291ms         9.25%       7.475ms       7.475ms     106.432us         0.13%       7.475ms       7.475ms             1  
                      aten::sum         0.08%      68.435us         0.10%      77.984us      38.992us       7.462ms         9.24%       7.462ms       3.731ms             2  
                   aten::linear         0.03%      26.145us         0.21%     173.527us     173.527us      65.918us         0.08%       7.369ms       7.369ms             1  
                   aten::matmul         0.03%      20.421us         0.13%     104.677us     104.677us      18.465us         0.02%       7.303ms       7.303ms             1  
                       aten::mm         0.10%      77.585us         0.10%      84.256us      84.256us       7.284ms         9.02%       7.284ms       7.284ms             1  
-------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  
Self CPU time total: 80.783ms
Self CUDA time total: 80.764ms

Epoch 00002 | Step 00000 | Loss 2.1792 | Train Acc 0.4110 | Speed (samples/sec) 2640.1100 | GPU 4242.2 MB
Epoch 00002 | Step 00020 | Loss 2.1523 | Train Acc 0.4190 | Speed (samples/sec) 2652.8634 | GPU 4242.2 MB
Epoch 00002 | Step 00040 | Loss 2.2831 | Train Acc 0.3950 | Speed (samples/sec) 2654.5460 | GPU 4242.2 MB
Epoch 00002 | Step 00060 | Loss 2.1393 | Train Acc 0.4310 | Speed (samples/sec) 2637.0482 | GPU 4242.2 MB
Epoch 00002 | Step 00080 | Loss 2.0515 | Train Acc 0.4590 | Speed (samples/sec) 2631.5369 | GPU 4242.2 MB
Epoch 00002 | Step 00100 | Loss 2.0039 | Train Acc 0.4570 | Speed (samples/sec) 2635.5471 | GPU 4242.2 MB
Epoch 00002 | Step 00120 | Loss 1.9206 | Train Acc 0.4770 | Speed (samples/sec) 2632.1457 | GPU 4242.2 MB
Epoch 00002 | Step 00140 | Loss 1.9654 | Train Acc 0.4800 | Speed (samples/sec) 2631.8632 | GPU 4242.2 MB
Epoch 00002 | Step 00160 | Loss 1.8836 | Train Acc 0.4870 | Speed (samples/sec) 2644.5671 | GPU 4242.2 MB
Epoch 00002 | Step 00180 | Loss 1.8626 | Train Acc 0.5160 | Speed (samples/sec) 2643.0257 | GPU 4242.2 MB
Epoch Time(s): 112.9213
Avg epoch time: -0.0
